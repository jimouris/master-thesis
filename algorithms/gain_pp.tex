\begin{algorithm}[H]\fontfamily{lmss}
\caption{Privacy Preserving Information Gain Algorithm}\label{a:id3-gain-pp}
\begin{algorithmic}[1]
\Require $\red{examples}, \red{example}, \red{gain}, \red{subset}, \red{percentage}$
\Procedure{InformationGain}{$\red{examples}, attribute$}\Comment{{\small Information gain (equation \ref{eq:gain}) is \par\hfill the measure of the difference in entropy from before to after a dataset is split on an attribute}}
    \State $\red{gain} \gets \textsc{Entropy}(\red{examples})$

    \For{{\small each possible value} $v_i$ {\small of} $attribute$}
        \State $\red{eq} \gets \red{examples}[attribute] \heq v_i$ \Comment{{\small ${\texttt{SIMD}; \red{eq}}$ vector gets $\enc{1}$ at positions \par\hfill where the equality holds, $\enc{0}$ otherwise}}
        \State $\red{subset} \gets \red{examples} \hmul \red{eq} \hplus (\enc{1} \hminus \red{eq}) \hmul \enc{-1} $ \Comment{{\small ${\texttt{SIMD}; \red{subset}}$ gets a copy of $\red{examples}$ \par\hfill at positions  where the equality holds, $\enc{-1}$ otherwise}}

        \State $\red{percentage} \gets \textsc{CountPositives}(\red{subset}) \hdiv \textsc{CountPositives}(\red{examples})$
        \State $\red{gain} \gets \red{gain} \hminus \red{percentage} \hmul \textsc{Entropy}(\red{subset})$
    \EndFor
    \State \textbf{return} $\red{gain}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
