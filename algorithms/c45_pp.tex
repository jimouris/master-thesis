\begin{algorithm}[H]\fontfamily{lmss}
\caption{Privacy Preserving C4.5 Algorithm}\label{a:c45-pp}
\begin{algorithmic}[1]
  \renewcommand{\algorithmicrequire}{\textbf{Private Vars:}}
  \Require $\red{examples}, {\red{allSame}}, \red{subset}, \red{less}, \red{greater}, \red{bestSplitted}$
  \renewcommand{\algorithmicrequire}{\textbf{Global Vars:}}
  \Require $classAttribute, categoricalAttributes$
\Procedure{C45}{$\red{examples}, attributes$}
    \If   {$attributes = \{\}$}\Comment{{\small If number of predicting attributes is empty}}
          \State \textbf{return} $\textsc{MostCommonLabel}(\red{examples})$\Comment{{\small Return the label with the most common \par\hfill value of the target attribute in the examples}}
    \ElsIf {${\blue{\textsc{Declassify}}}({\red{\textsc{AllExamplesSame}}}(\red{examples}))$}
      \State $\red{label} \gets \enc{-1}$
      \For{$\red{example} \in \red{examples}$}
          \State $\red{neq} \gets \red{example}[classAttribute] \hneq \enc{-1}$
          \State $\red{label} \gets \red{neq} \hmul \red{example}[classAttribute] \hplus (\enc{1} - \red{neq}) \hmul \red{label} $
      \EndFor
      \State \textbf{return} {{\blue{\textsc{Declassify}}}}$(\red{label})$
    \EndIf


    \State $(bestAttribute, bestThreshold, \red{bestSplitted}) \gets \textsc{Best}(\red{examples}, attributes)$\Comment{{\small Best \par\hfill attribute is the one whose split provides maximum information gain. $\red{bestSplitted}$ \par\hfill corresponds to the subsets generated by that split. }}
    \State $branches \gets \{\}$

    \algstore{myalg}
    \end{algorithmic}
    \end{algorithm}
    \begin{algorithm}
    \begin{algorithmic} [1]
    \algrestore{myalg}

    \If {$bestAttribute \in categoricalAttributes$}\Comment{{\small If best attribute is categorical}}
      \For{{\small each possible value} $v_i$ {\small of} $bestAttribute$}
          \State {\small Let} $branch$ {\small be a new tree branch corresponding to} $bestAttribute = v_i$
          \State $\red{subset} \gets \red{bestSplitted}[v_i]$

          \If {{\blue{\textsc{Declassify}}}$(\textsc{CountPositives}(subset) \heq \enc{0})$}
              \State $branch \gets \textsc{AddLeaf}(branch, \textsc{MostCommonLabel}(\red{examples})))$
          \Else
              \State $branch \gets \textsc{AddTree}(branch, \textsc{C45}(\red{subset},$ $attributes - \{bestAttribute\}))$\par\hfill
          \EndIf
          \State $branches \gets branches \cup branch$
      \EndFor
    \Else
      \State {\small Let} $branch$ {\small be a new tree branch corresponding to} $bestAttribute <= bestThreshold$
      \State $\red{less} \gets \red{bestSplitted}[0]$
      \If {{\blue{\textsc{Declassify}}}$(\textsc{CountPositives}(\red{less}) \heq \enc{0})$}
          \State $branch \gets \textsc{AddLeaf}(branch, \textsc{MostCommonLabel}(\red{examples})))$
      \Else
          \State $branch \gets \textsc{AddTree}(branch, \textsc{C45}(\red{less},$ $attributes - \{bestAttribute\}))$\par\hfill
      \EndIf
      \State $branches \gets branches \cup branch$
      \State {\small Let} $branch$ {\small be a new tree branch corresponding to} $bestAttribute > bestThreshold$
      \State $\red{greater} \gets \red{bestSplitted}[1]$
      \If {{\blue{\textsc{Declassify}}}$(\textsc{CountPositives}(\red{greater}) \heq \enc{0})$}
          \State $branch \gets \textsc{AddLeaf}(branch, \textsc{MostCommonLabel}(\red{examples})))$
      \Else
          \State $branch \gets \textsc{AddTree}(branch, \textsc{C45}(\red{greater},$ $attributes - \{bestAttribute\}))$\par\hfill
      \EndIf
      \State $branches \gets branches \cup branch$
    \EndIf
    \State \textbf{return} $branches$
\EndProcedure
\end{algorithmic}
\end{algorithm}

