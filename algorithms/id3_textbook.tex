\begin{algorithm}[H]
\caption{ID3 Textbook Algorithm \fixme{Change the textbook algorithm, make similar to the id3.py}}\label{a:id3-simple}
\begin{algorithmic}[1]

\Procedure{ID3\_Textbook}{$examples, class\_attribute, attributes$}
    \State Create a $root$ node for the tree
    \If {all examples are positive}
        \State \textbf{return} the single-node tree $root$, with label = +
    \ElsIf {all examples are negative}
        \State \textbf{return} the single-node tree $root$, with label = -
    \ElsIf {number of predicting attributes is empty}
        \State \textbf{return} the single-node tree $root$ with label = most common value of the target attribute in the examples
    \Else
        \State $A$ $\gets$ The Attribute that best classifies examples
        \State Decision Tree attribute for $root = A$

        \For{each possible value $v_i$ of $A$}
            \State Add a new tree branch below $root$, corresponding to the test $A = v_i$
            \State Let $examples(v_i)$ be the subset of examples that have the value $v_i$ for $A$
            \If {$examples(v_i)$ is empty}
                \State Then below this new branch add a leaf node with label = most common target value in the examples
            \Else
                \State below this new branch add the subtree \textsc{ID3\_Textbook}$(examples(v_i),$ $class\_attribute,$ $attributes - \{A\})$
            \EndIf
        \EndFor
    \EndIf
\EndProcedure

\end{algorithmic}
\end{algorithm}
