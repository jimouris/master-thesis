\begin{algorithm}[H]\fontfamily{lmss}
\caption{Entropy Textbook Algorithm}\label{a:id3-entropy-simple}
\begin{algorithmic}[1]
\renewcommand{\algorithmicrequire}{\textbf{Global Vars:}}
\Require $classAttribute$
\Procedure{Entropy}{$examples$}\Comment{{\small Entropy (H(S) equation \ref{eq:entropy}), is a measure of the \par\hfill amount of uncertainty in the dataset}}
    \State $entropy \gets 0$

    \For{{\small each possible value} $v_i$ {\small of} $classAttribute$}
        \State $count \gets$ {\small number of examples that} $examples[classAttribute] = v_i$

        \State $percentage \gets count \div \textsc{Length}(examples)$
        \If {$percentage \neq 0$}
            \State $entropy \gets entropy - (percentage * log_2 (percentage))$
        \EndIf
    \EndFor
    \State \textbf{return} $entropy$
\EndProcedure
\end{algorithmic}
\end{algorithm}
