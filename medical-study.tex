\chapter{A Medical Case Study}\label{c:medical-study}

In this thesis we primary focus to analyze medical data by using some of the aforementioned techniques from section \ref{c:preliminaries}.
More specifically we have developed a complete platform built around secure medical data analytics that could be beneficial to patients, doctors and researchers.

The platform can provide insights about some medical datasets that are imported into the platform to anyone who wants to query them, without compromising individual patient's privacy.
These analytics which include data aggregation / statistics and classification are implemented through privacy preserving algorithms under the secure multi-party computation scenario.

The platform provides end to end work flow starting from the query selection from a user.
Following is the secure data importing, the performing of privacy preserving data analytics algorithms upon those data and finally the visualization of the results to the end user through a friendly user interface (UI).

\section{A Doctor's view}
We consider the use case of a doctor working in a hospital that wants to examine the data stored in that hospital's datasets.
He/She could possibly want to evaluate a treatment's outcome.
To achieve this, the doctor should have monitored some particular datasets in order to have an overall view of the patients' condition over time.
This could allow a comparison between previously treated patients and enable data-driven cues for the treatment.
For example, a drug's effect could be evaluated that way.

The doctor could also compare aggregate results from datasets between different hospitals.
That way he/she could get an insight of how each patients' condition varies between different hospitals, which could indicate the different effect that different treatments have on patients and identify patterns
and differences in these treatments.

Continuous monitoring of patient data is useful for any hospital.
Provided with usable and informative tools a doctor could potentially make better diagnoses and take the appropriate action for each case.


\section{An Individual's view}
An individual could also benefit from the insights provided by our platform.
We consider the case in which an individual with a certain condition queries the available datasets looking for the same condition.
\fixme{The individual could locate the hospitals in which patients with the same condition are treated.
Also, he/she could identify which hospitals in his area have the best outcome for patients with conditions similar to his.
\textbf{How is this possible?? doesn't this compromise patients' data??}}


Another way an individual could be benefited from the privacy preserving medical data analytics is the use of a classification mechanism using a model trained over patient data.
This way one could classify himself to a condition / disease or another chosen attribute for that matter, based on his own data.


\section{A Researcher's view}
We examine the case where an academic or industry researcher queries the datasets to see if they suit their research needs.
They could discover if the datasets are providing enough utility / information and decide which ones to use for performing analysis on.

For example, studying aggregate statistical information of the datasets, one could find possible correlations of particular attributes or find patterns of treatments and conditions.

A researcher could also study the relation between certain conditions and different hospitals, which is something that could provide valuable information.



\section{Our architecture \fixme{give a fancy name for the whole scheme.}}\label{s:architecture}
Our architecture consists of the \textit{SMPC cluster}, a proxy server, dubbed \textit{coordinator}, as well as \texttt{N} more servers that are hosted in the hospitals' premises and act as \textit{data providers}.

\textbf{SMPC cluster}: The \textit{SMPC cluster} consists of three servers -- three computing nodes -- participating in the SMPC protocol. In our case, these nodes do not provide the data for the computation.

\textbf{Data providers}: The \textit{data providers} are hospitals that provide medical datasets upon which the privacy preserving algorithms will execute.
When the medical data are transferred from the hospitals to the computing nodes, they get secret\hyp shared.


\textbf{Coordinator}: The \textit{coordinator} handles all private computation requests.
The server listens for requests for private query execution, and when such a request arises, the coordinator communicates with the data providers (all \texttt{N} hospitals) requesting them to securely import their data to the computing cluster.
The data are then secret\hyp shared to the three nodes, with each node acquiring one share of the original value.
Then the privacy preserving computation takes place in the SMPC cluster, and the results get visualized and served back to the requesting user through the \textit{coordinator} server.


The detailed procedure is depicted in figure \ref{f:overview}.
First, an analyst sends a request to the \textit{coordinator} asking for a private computation, specifying an attribute and the hospitals from which the data will originate -- let us assume an aggregation over a field \texttt{X}, for hospitals \texttt{A} and \texttt{B}.
Then, the main server request from each selected hospital (in our case \texttt{A} and \texttt{B}) to import their data for attribute \texttt{X} to the SMPC cluster.
Consecutively, using an additive secret sharing protocol, the hospitals' servers securely import their data to the three computing nodes.
The actual computation takes place after the import is complete, and finally the aggregation over attribute \texttt{X} is returned to the user through the \textit{coordinator}.



\begin{figure}[t]
  \centering
  \includegraphics[width=\linewidth]{figures/overview.png}
  % \vspace{-0.2in}
  \caption{An overview of the architecture of our study \fixme{update to latest version: (not yet..)}}\label{f:overview}
\end{figure}



\subsection{SMPC Cluster Privacy Guarantees}\label{s:smpc-privacy-guarantees}

As we examined in section \ref{s:smpc}, the computing nodes of the \textit{SMPC cluster} do not need to be trusted nodes.
The only requirement of these nodes is not to collude.
This should not be confused with trusted servers.
A reasonable way to prevent collusion, is to deploy the computing nodes in premises of organizations having conflicting interests.


Since the actual data are transferred from the hospitals to the computing nodes through secret\hyp sharing, it is impossible for any of the three nodes to decrypt them, and in general to infer any information, as each computing node possesses only a share of the data.
However, meaningful computations can be applied due to the homomorphic properties that the shares have (section \ref{ss:secret-sharing-homomorphism}).

The only information that gets published is the output of the privacy preserving computation.
This is returned to the user who initiated the query via the \textit{coordinator} server.


\section{Data Importing}\label{s:importing}
The data importing is a procedure of high importance, since the patients' data are transferred outside the hospitals to third party servers.
It is easily misinterpreted that since the data are leaving the hospitals' premises, their privacy is being compromised.
However, it has been elucidated in section \ref{s:secret-sharing} that secret sharing is a form of encryption, thus no information leakage is possible while data being in use in the SMPC cluster.
For transferring each share from the data providers to the corresponding SMPC computing nodes standard techniques -- such as symmetric encryption -- are used to protect data in transit.
Data are also safe while at rest in the SMPC cluster as each node only stores a cryptographic share of a piece of data, so no information about the original data can be inferred.



\subsection{Data Importing On-the-Fly}\label{s:importing-otf}
Everyday, thousands of people visit their doctors, updating their medical records with new diagnoses.
One may wonder, \textit{since the medical data of each hospital are constantly changing, how often should the datasets in the SMPC cluster be updated?}

In our architecture, we have developed a mechanism for data importing \textit{on-the-fly}, as figure \ref{f:overview} portrays.
More specifically, when a query is requested for private computation, the coordinator interacts with the hospitals' servers, initiating the data import procedure.
Since the individual making the query also selects some specific attributes for data aggregation and/or classification, the importing of the data only happens for the selected attributes.

This importing on-the-fly is beneficial for many reasons.
First and foremost, all private computations are evaluated over the most recent data, and not in a former version of them.
An alternative could be to update the imported data over small time periods, however, in this case the results from the secure multi-party computation would not represent the actual data.

\fixme{needs rephrase...}
Another reason is that the actual datasets are huge compared to the requested attributes.
Each meaningful request does not take into account every possible attribute from the dataset, thus there is no purpose importing everythin a priori.


Finally, \fixme{add here the technical reason for data import on the fly?? json files etc...?}


\section{Supported Computations}\label{s:computations}
\fixme{General description of hist, id3. Details in \ref{c:pp-algorithms}
}

\fixme{what is a histogram/count and why it is usefull?}

\fixme{what is a classification tree and why it is usefull?}



