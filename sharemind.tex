\chapter{Sharemind: A Secure Computing Platform}\label{c:sharemind}

Sharemind \cite{bogdanov2008sharemind, bogdanov2013sharemind} is a general purpose SMPC system, for privacy preserving data processing operating on additively secret-shared values.
The idea of Sharemind is to provide a secure infrastructure that is able to host and evaluate privacy preserving algorithms.
Sharemind provides an easily programmable and flexible platform that enables non\hyp cryptographers to develop and test privacy preserving algorithms such as Privacy Preserving Data Mining (PPDM).
It consists of the computation runtime environment and a programming library for creating private data processing applications
Sharemind is provably secure under the semi-honest (honest but curious) setting.

Sharemindâ€™s is deployed as a distributed computation platform, that can be used both for data storage and computation.
The deployment model consists of (usually three) nodes, the computing nodes that use SMPC through secret sharing to privately process the data.
Secret sharing guarantees data confidentiality during storage.
All computations are done by the dedicated computing nodes.

Data providers submit their private inputs by sending the corresponding cryptographic shares to the computing nodes.
The secret sharing scheme ensures that each share is a random bit string.
Each host, computing node, is not able to decrypt the data, or even extract any information about them.
Consequently, a node holding that share learns no extra information about the data input (secret), than if they did not hold that share.
For that reason, data providers need not trust any of the computing nodes.
Instead providers must trust that the nodes as a group obey a set of rules such as that they do not collude during the computations.
This can be achieved through physical and organizational security measures as well as software auditing.
In practice, the computing nodes will be servers run by independent entities, such as companies or government agencies, ideally having conflicting interests.
Data users want to analyze the information given by data providers.
Answers to their queries are given through the Sharemind system, and not from data providers directly.


The Sharemind framework provides a privacy preserving  instruction set which includes secure addition, multiplication and greater\hyp than\hyp or\hyp equal comparison of two shared values.
Multiplication of a shared value with a constant and extraction of its bits as shares is also possible.
Bit extraction and arithmetic primitives are sufficient to construct any Boolean circuit with a linear overhead and thus the Sharemind framework is also Turing complete \cite{bogdanov2008sharemind}.
Many data mining and statistical analysis algorithms use no other mathematical operations than the Sharemind's instruction set, thus it is sufficient for most applications.

\section{SecreC}

The programmer of the privacy preserving applications does not necessarily know the underlying security protocols.
Application are developed using the SecreC programming language \cite{jagomagis2010secrec}.
SecreC is an procedural imperative domain specific language (DSL) that is syntactically similar to C. SecreC guarantees writing privacy-preserving algorithms without any knowledge of the underlying cryptographic protocol.
In other words, SecreC distinguishes the application / business logic from the cryptographic protocol.

The language uses a custom type system, which separates private / confidential data from public.
Public values are processed as usual, whereas private values, which are in secret-shared form are processed using secure computation.
To achieve this, SecreC adds a security type to each fundamental data type.
The security type can be either \textit{private} or \textit{public}.
If no security type is specified then the public one is used by default.
Security types differ from standard data types in the sense that data associated with the public security type will be stored and processed publicly on the Sharemind virtual machine, whereas data associated with the private security type, will be stored in secret\hyp shared form.
Each computing node will acquire one share of the actual value.

In SecreC one can have expressions or private or public data.
In the case that such two expressions are combined into a single expression something needs to be done in order for the composite expression to be evaluated.
In that case the public data are secret\hyp shared and moved into the private execution environment.
That way all data are of the private security type and the expression can be evaluated.

Sometimes however it is vital to open a secret.
This could be done in order to gain some insight about an algorithm having good intentions in mind.
SecreC offers a special \texttt{declassify} operator through which is made possible to publish private information.
An expression that is  \fixme{\texttt{declassif}\hyp ied} has its security type changed from private to public, and the secret\hyp shared value moves into the public execution environment.
Since the use of the \texttt{declassify} operator is the only way for private data to become public, its use should be tracked in order to reason about data privacy and to avoid potential unwanted privacy leaks.
As a rule of thumb, declassification of private data should occur ass little as possible.
Ideally, declassification should be used only to publish the final results of an algorithm, or intermediate results that have low privacy risk \textit{i.e.} do not reveal sensitive information.

Typically, if a decision (e.g a branch) is to be made over private data, that would require the data to be published, that is to be converted to the public security type.
There is however an alternative solution to branching on private information.
For instance, consider the following example:

\texttt{if (x) a = b; else a = c; }

One can rewrite the previous statement using with the following expression:

\texttt{a = b * x + c * (1-x); }

Using this technique a programmer can replace conditional statements on private data with such oblivious selection clauses.
So the control flow dependencies are converted into data dependencies.

An example of SecreC code can be found below.
The problem at hand is Yao's millionaire problem \cite{yao1982protocols} as described in section \ref{s:smpc}.
Here we use \texttt{pd\_shared3p} as the security type, which stands for \textit{\textbf{p}rotection \textbf{d}omain \textbf{shared 3 p}arties}, and corresponds to a private security type using secret\hyp sharing between three parties.

\begin{minted}[linenos,tabsize=2,breaklines,breaksymbolleft=,fontsize=\footnotesize]{c++}
pd_shared3p uint64 max(pd_shared3p uint64 x, pd_shared3p uint64 y) {
  pd_shared3p uint64 gt = (uint64)(x > y);  // 1 if x > y, 0 otherwise
  return x * gt + y * (1-gt);               // Oblivious selection of the max value
}

void main(){
  pd_shared3p uint64 x1 = 5;            // Private, secret-shared value of input party 1
  pd_shared3p uint64 x2 = 8;            // Private, secret-shared value of input party 2
  pd_shared3p uint64 max = max(x1, x2); // Private result
  print(declassify(max));               // Result publishing
}

\end{minted}
\captionof{listing}{Millionaire problem in SecreC}


